import os
import json
import re
import base64
from typing import List, Dict
import httpx
import google.generativeai as genai
from cache_manager import get_cache_instance

class ChatbotAssistant:
    def __init__(self, gemini_api_key: str = None, openrouter_api_key: str = None):
        """
        Initialize ChatbotAssistant v·ªõi th·ª© t·ª± ∆∞u ti√™n: Gemini ‚Üí OpenRouter
        
        Args:
            gemini_api_key: Gemini Direct API key (Primary)
            openrouter_api_key: OpenRouter API key (Fallback)
        """
        if not gemini_api_key and not openrouter_api_key:
            raise ValueError("C·∫ßn √≠t nh·∫•t m·ªôt trong hai: GEMINI_API_KEY ho·∫∑c OPENROUTER_API_KEY")
        
        self.gemini_api_key = gemini_api_key  # Gemini Direct API (Primary)
        self.openrouter_api_key = openrouter_api_key  # OpenRouter API (Fallback)
        self.base_url = "https://openrouter.ai/api/v1"
        self.openrouter_model = "google/gemini-2.0-flash-exp:free"
        # Try gemini-1.5-flash-latest first, fallback to gemini-pro if not available
        self.gemini_model_name = "gemini-1.5-flash-latest"  # Gemini model
        
        # Gemini Direct API setup (lazy-load)
        self.gemini_model = None
        if gemini_api_key:
            try:
                genai.configure(api_key=gemini_api_key)
                print("‚úÖ Gemini Direct API configured as PRIMARY")
            except Exception as e:
                print(f"‚ö†Ô∏è  Gemini Direct API config failed: {e}")
        
        # T·ªëi ∆∞u system prompt - gi·∫£m t·ª´ ~100 d√≤ng xu·ªëng ~30 d√≤ng ƒë·ªÉ ti·∫øt ki·ªám token
        self.system_prompt = """B·∫°n l√† tr·ª£ l√Ω AI chuy√™n gia dinh d∆∞·ª°ng & s·ª©c kh·ªèe cho ·ª©ng d·ª•ng My Diary.

PH·∫†M VI: Ch·ªâ tr·∫£ l·ªùi v·ªÅ dinh d∆∞·ª°ng, th·ª©c ƒÉn, ƒë·ªì u·ªëng, s·ª©c kh·ªèe, thu·ªëc, ch·∫ø ƒë·ªô ƒÉn. T·ª´ ch·ªëi l·ªãch s·ª± c√°c c√¢u h·ªèi ngo√†i ph·∫°m vi.

NGUY√äN T·∫ÆC:
- ∆Øu ti√™n th·ª±c ph·∫©m Vi·ªát Nam
- Ng·∫Øn g·ªçn, d·ªÖ hi·ªÉu, d·ª±a tr√™n khoa h·ªçc
- Kh√¥ng ƒë∆∞a ch·∫©n ƒëo√°n y khoa hay k√™ ƒë∆°n
- N·∫øu kh√¥ng ch·∫Øc ‚Üí khuy√™n tham kh·∫£o chuy√™n gia

ƒê·ªäNH D·∫†NG: Tr·∫£ v·ªÅ vƒÉn b·∫£n thu·∫ßn ti·∫øng Vi·ªát, kh√¥ng markdown, kh√¥ng k√Ω t·ª± bi·ªÉu t∆∞·ª£ng. ∆Øu ti√™n JSON n·∫øu c√≥ th·ªÉ, n·∫øu kh√¥ng th√¨ plain text."""
        
        print(f"‚úÖ ChatbotAssistant initialized with fallback chain")
        if self.gemini_api_key:
            print(f"‚úÖ Primary: Gemini Direct ({self.gemini_model_name})")
        if self.openrouter_api_key:
            print(f"‚úÖ Fallback: OpenRouter ({self.openrouter_model})")
        print("System prompt: T·ªëi ∆∞u token (~30 d√≤ng thay v√¨ ~100 d√≤ng)\n")

    async def get_response(self, question: str, history: List[Dict[str, str]] = None) -> str:
        """
        Get response v·ªõi fallback chain: OpenRouter ‚Üí OpenAI ‚Üí Gemini
        Ch·ªâ d√πng cho chat, kh√¥ng d√πng cho ph√¢n t√≠ch h√¨nh ·∫£nh
        """
        if not question.strip():
            raise ValueError("C√¢u h·ªèi kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng")

        # Build messages array (t·ªëi ∆∞u: ch·ªâ l·∫•y 5-10 messages g·∫ßn nh·∫•t ƒë·ªÉ gi·∫£m token)
        messages = [{"role": "system", "content": self.system_prompt}]

        # Limit history to last 10 messages to save tokens
        if history:
            limited_history = history[-10:] if len(history) > 10 else history
            for msg in limited_history:
                role = msg.get("role", "")
                content = msg.get("content", "")
                if role and content and role in ["user", "assistant"]:
                    messages.append({"role": role, "content": content})

        messages.append({"role": "user", "content": question})

        # Fallback chain: Gemini ‚Üí OpenRouter
        last_error = None
        
        # Try 1: Gemini Direct (Primary)
        gemini_error = None
        if self.gemini_api_key:
            # First, try to list available models
            available_models = []
            try:
                print("üîç Listing available Gemini models...")
                for model in genai.list_models():
                    if 'generateContent' in model.supported_generation_methods:
                        model_name = model.name.replace('models/', '')
                        available_models.append(model_name)
                        print(f"   ‚úÖ Found: {model_name}")
                
                if available_models:
                    print(f"üìã Using first available model: {available_models[0]}")
                    gemini_models = available_models
                else:
                    # Fallback to common model names if list_models fails
                    gemini_models = [
                        "gemini-pro",
                        "gemini-1.5-pro",
                        "gemini-1.5-flash",
                        "models/gemini-pro",
                        "models/gemini-1.5-pro"
                    ]
            except Exception as list_error:
                print(f"‚ö†Ô∏è  Could not list models: {list_error}")
                # Fallback to common model names
                gemini_models = [
                    "gemini-pro",
                    "gemini-1.5-pro", 
                    "gemini-1.5-flash",
                    "models/gemini-pro",
                    "models/gemini-1.5-pro"
                ]
            
            for model_name in gemini_models:
                try:
                    print(f"üîÑ Trying Gemini Direct (Primary) with {model_name}...")
                    # Create new model instance for each try
                    test_model = genai.GenerativeModel(model_name)
                    
                    # Build prompt with system message and history
                    full_prompt = self.system_prompt + "\n\n"
                    
                    # Add history
                    for msg in messages[1:-1]:  # Skip system and last user message
                        role = msg["role"]
                        content = msg["content"]
                        if role == "user":
                            full_prompt += f"User: {content}\n"
                        elif role == "assistant":
                            full_prompt += f"Assistant: {content}\n"
                    
                    # Add current question
                    full_prompt += f"User: {question}\nAssistant:"
                    
                    # Try generate_content directly (simpler approach)
                    response = test_model.generate_content(full_prompt)
                    text = response.text.strip() if response.text else None
                    
                    if text:
                        print(f"‚úÖ Success with Gemini Direct ({model_name})")
                        # Save working model for next time
                        self.gemini_model = test_model
                        self.gemini_model_name = model_name
                        return self._process_response(text)
                    else:
                        raise ValueError("Empty response from Gemini")
                        
                except Exception as e:
                    gemini_error = str(e)
                    error_msg = str(e)
                    # Check if it's an API not enabled error
                    if "API key not valid" in error_msg or "not enabled" in error_msg.lower():
                        print(f"‚ùå Gemini API error: {error_msg}")
                        print("üí° HINT: Make sure Gemini API is enabled in Google Cloud Console")
                        print("   Visit: https://makersuite.google.com/app/apikey")
                    elif "404" in error_msg or "not found" in error_msg.lower():
                        print(f"‚ùå Model {model_name} not found: {error_msg[:100]}")
                    else:
                        print(f"‚ùå Gemini Direct failed with {model_name}: {error_msg[:200]}")
                    # Try next model
                    continue
            
            # All Gemini models failed
            if gemini_error:
                last_error = f"Gemini Direct: {gemini_error}"
                print(f"‚ùå All Gemini models failed. Last error: {last_error}")
        
        # Try 2: OpenRouter (Fallback)
        if self.openrouter_api_key:
            try:
                print("üîÑ Falling back to OpenRouter...")
                async with httpx.AsyncClient(timeout=60.0) as client:
                    response = await client.post(
                        f"{self.base_url}/chat/completions",
                        headers={
                            "Authorization": f"Bearer {self.openrouter_api_key}",
                            "Content-Type": "application/json",
                            "HTTP-Referer": "https://mydiary.app",
                            "X-Title": "My Diary Nutrition App"
                        },
                        json={"model": self.openrouter_model, "messages": messages}
                    )
                
                    if response.status_code == 200:
                        result = response.json()
                        if "choices" in result and len(result["choices"]) > 0:
                            text = result["choices"][0]["message"]["content"].strip()
                            if text:
                                print("‚úÖ Success with OpenRouter")
                                return self._process_response(text)
                    else:
                        # Rate limit or error
                        if response.status_code == 429:
                            raise ValueError(f"OpenRouter rate limited: {response.text}")
                        else:
                            raise ValueError(f"OpenRouter error {response.status_code}: {response.text}")
                        
            except Exception as e:
                last_error = str(e)
                print(f"‚ùå OpenRouter failed: {last_error}")
        
        # All providers failed
        raise ValueError(f"T·∫•t c·∫£ providers ƒë·ªÅu th·∫•t b·∫°i. L·ªói cu·ªëi: {last_error}")
    
    def _process_response(self, text: str) -> str:
        """Process v√† prettify response text"""
        try:
            parsed = json.loads(text)
            # Build pretty text from JSON
            parts = []
            if isinstance(parsed, dict):
                if parsed.get('title'):
                    parts.append(parsed.get('title').strip())
                    parts.append('')
                if parsed.get('summary'):
                    parts.append(parsed.get('summary').strip())
                    parts.append('')
                if parsed.get('bullets') and isinstance(parsed.get('bullets'), list):
                    bullets = [b.strip().rstrip('.') for b in parsed.get('bullets') if b]
                    if bullets:
                        parts.append('B·∫°n n√™n: ' + ', '.join(bullets) + '.')
                        parts.append('')
                if parsed.get('meals') and isinstance(parsed.get('meals'), list):
                    parts.append('\n'.join([m.strip() for m in parsed.get('meals') if m]))
                    parts.append('')
                if parsed.get('notes'):
                    parts.append('Ghi ch√∫: ' + parsed.get('notes').strip())
            
            pretty = '\n'.join([p for p in parts if p is not None and p != ''])
            return pretty if pretty else self._prettify_text(text)
        except:
            return self._prettify_text(text)

    def _prettify_text(self, raw: str) -> str:
        """C·ªë g·∫Øng chuy·ªÉn c√°c bullet/markdown th√†nh ƒëo·∫°n vƒÉn ti·∫øng Vi·ªát ƒë·∫πp h∆°n."""
        if not raw or not raw.strip():
            return raw

        s = raw
        # Remove bold/markdown markers
        s = s.replace('**', '')
        s = s.replace('`', '')
        # Remove common icons
        s = re.sub(r'[‚Ä¢*+\-‚úÖ‚ùå]', '', s)

        # Normalize newlines and trim spaces
        lines = [ln.strip() for ln in re.split(r'[\r\n]+', s) if ln.strip()]
        if not lines:
            return s.strip()

        paragraphs = []
        i = 0
        while i < len(lines):
            line = lines[i]
            # If line ends with ':' treat following lines as list -> join with commas
            if line.endswith(':') or re.search(r'^(N√™n|∆Øu|H·∫°n ch·∫ø|G·ª£i √Ω|G·ª£i √Ω b·ªØa|B·∫°n n√™n|N√™n h·∫°n ch·∫ø)', line, re.I):
                header = line.rstrip(':').strip()
                items = []
                j = i + 1
                while j < len(lines) and not lines[j].endswith(':'):
                    items.append(lines[j].strip())
                    j += 1
                if items:
                    clean_items = [re.sub(r'^[\-\*\u2022\+\s]+', '', it).strip().rstrip('.') for it in items]
                    para = header + ': ' + ', '.join(clean_items) + '.'
                    paragraphs.append(para)
                    i = j
                    continue
            # Default: treat as normal paragraph
            paragraphs.append(line)
            i += 1

        pretty = '\n\n'.join(paragraphs)
        # Final cleanup: collapse multiple spaces
        pretty = re.sub(r'\s{2,}', ' ', pretty)
        return pretty.strip()

    async def analyze_food_image(self, image_bytes: bytes, filename: str = "default") -> dict:
        """
        Ph√¢n t√≠ch h√¨nh ·∫£nh th·ª©c ƒÉn/ƒë·ªì u·ªëng - CH·ªà D√ôNG MOCK DATA (kh√¥ng g·ªçi API ƒë·ªÉ ti·∫øt ki·ªám token)
        
        Args:
            image_bytes: Byte content c·ªßa h√¨nh ·∫£nh (kh√¥ng s·ª≠ d·ª•ng, ch·ªâ ƒë·ªÉ t∆∞∆°ng th√≠ch)
            filename: T√™n file ƒë·ªÉ match v·ªõi mock data
        
        Returns:
            {
                "items": [
                    {
                        "item_name": "Ph·ªü B√≤",
                        "item_type": "food",
                        "confidence_score": 92.5,
                        "estimated_volume_ml": 500,
                        "estimated_weight_g": 600,
                        "water_ml": 400,
                        "nutrients": {
                            "enerc_kcal": 350,
                            "procnt": 25,
                            ... (76 nutrients)
                        }
                    }
                ]
            }
        """
        print("üì∏ Image analysis: Using MOCK DATA only (no API calls to save tokens)")
        
        # Import mock data function
        from mock_nutrition_data import get_mock_nutrition_by_filename
        
        # Get mock data based on filename
        mock_result = get_mock_nutrition_by_filename(filename)
        
        # Convert to analyze-image format
        nutrients_obj = {}
        for nutrient in mock_result.get("nutrients", []):
            code = nutrient["nutrient_code"]
            # Remove MIN_ prefix from minerals
            if code.startswith("MIN_"):
                code = code.replace("MIN_", "")
            # Convert to lowercase
            code = code.lower()
            nutrients_obj[code] = nutrient["amount"]
        
        # Ensure all 76 nutrients exist (fill missing with 0)
        nutrient_keys = [
            "enerc_kcal", "procnt", "fat", "chocdf",
            "fibtg", "fib_sol", "fib_insol", "fib_rs", "fib_bglu",
            "cholesterol",
            "vita", "vitd", "vite", "vitk", "vitc",
            "vitb1", "vitb2", "vitb3", "vitb5", "vitb6", "vitb7", "vitb9", "vitb12",
            "ca", "p", "mg", "k", "na", "fe", "zn", "cu", "mn", "i", "se", "cr", "mo", "f",
            "fams", "fapu", "fasat", "fatrn", "faepa", "fadha", "faepa_dha", "fa18_2n6c", "fa18_3n3",
            "amino_his", "amino_ile", "amino_leu", "amino_lys", "amino_met",
            "amino_phe", "amino_thr", "amino_trp", "amino_val",
            "ala", "epa_dha", "la"
        ]
        
        for key in nutrient_keys:
            if key not in nutrients_obj:
                nutrients_obj[key] = 0
        
        # Random confidence between 90-95%
        import random
        random_confidence = random.uniform(0.90, 0.95)
        
        # Simulate processing delay (1-2 seconds)
        import asyncio
        await asyncio.sleep(random.uniform(1, 2))
        
        result = {
            "items": [{
                "item_name": mock_result.get("food_name", "M√≥n ƒÉn"),
                "item_type": "food",
                "confidence_score": random_confidence,
                "estimated_volume_ml": 250,
                "estimated_weight_g": 200,
                "water_ml": nutrients_obj.get("water", 0),
                "nutrients": nutrients_obj
            }]
        }
        
        print(f"‚úÖ Mock analysis complete: {mock_result.get('food_name', 'Unknown')}")
        return result
